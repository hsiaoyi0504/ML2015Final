{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from sklearn import linear_model, preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def E_abs(y_predict,y):\n",
    "    E=0\n",
    "    for i in range(len(y)):\n",
    "        E+=abs(y_predict[i]-y[i])\n",
    "    return E/len(y)\n",
    "\n",
    "def E_01(y_predict,y):\n",
    "    y_temp=[]\n",
    "    for i in range(len(y)):\n",
    "        if y_predict[i]>=0.5:\n",
    "            y_temp.append(1)\n",
    "        else:\n",
    "            y_temp.append(0)\n",
    "    return E_abs(y_temp,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read training features\n",
    "x=[]\n",
    "temp=0\n",
    "with open(\"../../data/ML_final_project/sample_train_x.csv\") as f:\n",
    "    for row in csv.reader(f):\n",
    "        if temp==0:\n",
    "            for i in range(len(row)): \n",
    "                x.append([])\n",
    "            temp+=1\n",
    "        else:\n",
    "            for i,value in enumerate(row):\n",
    "                x[i].append(float(value))\n",
    "    f.close()\n",
    "x=np.array(x)\n",
    "x=np.transpose(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read training truth\n",
    "y=[]\n",
    "with open('../../data/ML_final_project/truth_train.csv') as f:\n",
    "    reader=csv.reader(f)\n",
    "    for row in reader:\n",
    "        for i, value in enumerate(row):\n",
    "            if i!=0:\n",
    "                y.append(float(value))\n",
    "    f.close()\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#preprocessing the training data\n",
    "# preprocessing.normalize(x, norm='l2')\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# x=min_max_scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_Eval_01: 0.142717462606 best_n_components 15 best_c: 0.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training\n",
    "n_folds=10\n",
    "c_list=list(range(-4,5))\n",
    "c_list[:]=[10 ** x for x in c_list]\n",
    "n_components_list=range(10,18)\n",
    "best_Eval_01=1\n",
    "for c in c_list:\n",
    "    for n_components in n_components_list:\n",
    "        Ein_01=[]\n",
    "        Ein_abs=[]\n",
    "        Eval_01=[]\n",
    "        Eval_abs=[]\n",
    "        kf=KFold(len(x),n_folds=n_folds)\n",
    "        for train_index, val_index in kf:\n",
    "            x_train, x_val = x[train_index], x[val_index]\n",
    "            y_train, y_val = y[train_index], y[val_index]\n",
    "            pca = PCA(n_components=n_components)\n",
    "            pca.fit(x_train)\n",
    "            x_train_reduce = pca.transform(x_train)\n",
    "            logistic = linear_model.LogisticRegression(C=c)\n",
    "            logistic.fit(x_train_reduce,y_train)\n",
    "            y_train_predict = logistic.predict(x_train_reduce)\n",
    "            Ein_01.append(E_01(y_train_predict,y_train))\n",
    "            Ein_abs.append(E_abs(y_train_predict,y_train))\n",
    "            x_val_reduce = pca.transform(x_val)\n",
    "            y_val_predict = logistic.predict(x_val_reduce)\n",
    "            Eval_01.append(E_01(y_val_predict,y_val))\n",
    "            Eval_abs.append(E_abs(y_val_predict,y_val))\n",
    "        if sum(Eval_01)/n_folds<best_Eval_01:\n",
    "            best_Eval_01=sum(Eval_01)/n_folds\n",
    "            best_n_components=n_components\n",
    "            best_c=c\n",
    "print(\"best_Eval_01:\",best_Eval_01,\"best_n_components\",best_n_components,\"best_c:\",best_c)\n",
    "pca = PCA(n_components=best_n_components)\n",
    "pca.fit(x)\n",
    "x_reduce = pca.transform(x)\n",
    "logistic = linear_model.LogisticRegression(C=best_c)\n",
    "logistic.fit(x_reduce,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read testing data\n",
    "x_test=[]\n",
    "temp=0\n",
    "with open('../../data/ML_final_project/sample_test_x.csv') as f:\n",
    "    for row in csv.reader(f):\n",
    "        if temp==0:\n",
    "            for i in range(len(row)): \n",
    "                x_test.append([])\n",
    "            temp+=1\n",
    "        else:\n",
    "            for i,value in enumerate(row):\n",
    "                x_test[i].append(float(value))\n",
    "    f.close()\n",
    "x_test=np.array(x_test)\n",
    "x_test=np.transpose(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#predict testing data\n",
    "x_test_reduce=pca.transform(x_test)\n",
    "y_test_predict = logistic.predict(x_test_reduce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_track1=np.vstack((x_test[:,0],y_test_predict))\n",
    "output_track1=np.transpose(output_track1)\n",
    "output_track2=np.copy(output_track1)\n",
    "for i in range(len(output_track2)):\n",
    "    if output_track2[i][1]>=0.5:\n",
    "        output_track2[i][1]=1\n",
    "    else:\n",
    "        output_track2[i][1]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#write predict result to file\n",
    "with open(\"../../result/PCA_logisticReg/test_track1.csv\",\"w\") as f:\n",
    "    w=csv.writer(f)\n",
    "    w.writerows(output_track1)\n",
    "    f.close()\n",
    "with open(\"../../result/PCA_logisticReg/test_track2.csv\",\"w\") as f:\n",
    "    w=csv.writer(f)\n",
    "    w.writerows(output_track2)\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
