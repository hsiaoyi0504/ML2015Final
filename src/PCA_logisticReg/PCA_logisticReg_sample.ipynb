{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import random as rand\n",
    "from sklearn import linear_model, preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def E_abs(y_predict,y):\n",
    "    E=0\n",
    "    for i in range(len(y)):\n",
    "        E+=abs(y_predict[i]-y[i])\n",
    "    return E/len(y)\n",
    "\n",
    "def E_01(y_predict,y):\n",
    "    y_temp=[]\n",
    "    for i in range(len(y)):\n",
    "        if y_predict[i]>0.5:\n",
    "            y_temp.append(1)\n",
    "        elif y_predict[i]==0.5:\n",
    "            y_temp.append(rand.randint(0,1))\n",
    "        else:\n",
    "            y_temp.append(0)\n",
    "    return E_abs(y_temp,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read training features\n",
    "x=[]\n",
    "temp=0\n",
    "with open(\"../../data/ML_final_project/sample_train_x.csv\") as f:\n",
    "    for row in csv.reader(f):\n",
    "        if temp==0:\n",
    "            for i in range(len(row)): \n",
    "                x.append([])\n",
    "            temp+=1\n",
    "        else:\n",
    "            for i,value in enumerate(row):\n",
    "                x[i].append(float(value))\n",
    "    f.close()\n",
    "x=np.array(x)\n",
    "dimensions=len(x)\n",
    "x=np.transpose(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read training truth\n",
    "y=[]\n",
    "with open('../../data/ML_final_project/truth_train.csv') as f:\n",
    "    reader=csv.reader(f)\n",
    "    for row in reader:\n",
    "        for i, value in enumerate(row):\n",
    "            if i!=0:\n",
    "                y.append(float(value))\n",
    "    f.close()\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#preprocessing the training data\n",
    "# preprocessing.normalize(x, norm='l2')\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# x=min_max_scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#training\n",
    "n_folds=10\n",
    "c_list=list(range(-4,5))\n",
    "c_list[:]=[10 ** x for x in c_list]\n",
    "n_components_list=range(10,dimensions)\n",
    "best_Eval_01=1\n",
    "best_Eval_abs=1\n",
    "for c in c_list:\n",
    "    for n_components in n_components_list:\n",
    "        Ein_01=[]\n",
    "        Ein_abs=[]\n",
    "        Eval_01=[]\n",
    "        Eval_abs=[]\n",
    "        kf=KFold(len(x),n_folds=n_folds)\n",
    "        for train_index, val_index in kf:\n",
    "            x_train, x_val = x[train_index], x[val_index]\n",
    "            y_train, y_val = y[train_index], y[val_index]\n",
    "            pca = PCA(n_components=n_components)\n",
    "            pca.fit(x_train)\n",
    "            x_train_reduce = pca.transform(x_train)\n",
    "            logistic = linear_model.LogisticRegression(C=c)\n",
    "            logistic.fit(x_train_reduce,y_train)\n",
    "            y_train_predict = logistic.predict_proba(x_train_reduce)\n",
    "            y_train_predict = y_train_predict[:,1]\n",
    "            Ein_01.append(E_01(y_train_predict,y_train))\n",
    "            Ein_abs.append(E_abs(y_train_predict,y_train))\n",
    "            x_val_reduce = pca.transform(x_val)\n",
    "            y_val_predict = logistic.predict_proba(x_val_reduce)\n",
    "            y_val_predict = y_val_predict[:,1]\n",
    "            Eval_01.append(E_01(y_val_predict,y_val))\n",
    "            Eval_abs.append(E_abs(y_val_predict,y_val))\n",
    "        if sum(Eval_01)/n_folds<best_Eval_01:\n",
    "            best_Eval_01=sum(Eval_01)/n_folds\n",
    "            best_n_components_01=n_components\n",
    "            best_c_01=c\n",
    "        if sum(Eval_abs)/n_folds<best_Eval_abs:\n",
    "            best_Eval_abs=sum(Eval_01)/n_folds\n",
    "            best_n_components_abs=n_components\n",
    "            best_c_abs=c\n",
    "print(\"best_Eval_01:\",best_Eval_01,\"best_n_components\",best_n_components_01,\"best_c:\",best_c_01)\n",
    "print(\"best_Eval_abs:\",best_Eval_abs,\"best_n_components\",best_n_components_abs,\"best_c:\",best_c_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read testing data\n",
    "x_test=[]\n",
    "temp=0\n",
    "with open('../../data/ML_final_project/sample_test_x.csv') as f:\n",
    "    for row in csv.reader(f):\n",
    "        if temp==0:\n",
    "            for i in range(len(row)): \n",
    "                x_test.append([])\n",
    "            temp+=1\n",
    "        else:\n",
    "            for i,value in enumerate(row):\n",
    "                x_test[i].append(float(value))\n",
    "    f.close()\n",
    "x_test=np.array(x_test)\n",
    "x_test=np.transpose(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#training(track 1)\n",
    "pca = PCA(n_components=best_n_components_abs)\n",
    "pca.fit(x)\n",
    "x_reduce = pca.transform(x)\n",
    "logistic = linear_model.LogisticRegression(C=best_c_abs)\n",
    "logistic.fit(x_reduce,y)\n",
    "#predict testing data\n",
    "x_test_reduce=pca.transform(x_test)\n",
    "y_test_predict = logistic.predict_proba(x_test_reduce)\n",
    "y_test_predict = y_test_predict[:,1]\n",
    "output_track1=np.vstack((x_test[:,0],y_test_predict))\n",
    "output_track1=np.transpose(output_track1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#write predict result to file\n",
    "with open(\"../../result/PCA_logisticReg/test_track1.csv\",\"w\") as f:\n",
    "    w=csv.writer(f)\n",
    "    w.writerows(output_track1)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training(track 2)\n",
    "pca = PCA(n_components=best_n_components_01)\n",
    "pca.fit(x)\n",
    "x_reduce = pca.transform(x)\n",
    "logistic = linear_model.LogisticRegression(C=best_c_01)\n",
    "logistic.fit(x_reduce,y)\n",
    "#predict testing data\n",
    "x_test_reduce=pca.transform(x_test)\n",
    "y_test_predict = logistic.predict(x_test_reduce)\n",
    "output_track2=np.vstack((x_test[:,0],y_test_predict))\n",
    "output_track2=np.transpose(output_track2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"../../result/PCA_logisticReg/test_track2.csv\",\"w\") as f:\n",
    "    w=csv.writer(f)\n",
    "    w.writerows(output_track2)\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
